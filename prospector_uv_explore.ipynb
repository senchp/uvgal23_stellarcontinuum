{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8cd43d-2874-4aff-8f76-46f9e5268489",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this tutorial notebook, we'll go through the basic setup for using prospector to fit some UV spectra. Note that prospector is one of many tools in this space that can work directly with spectra (see also BEAGLE, Bagpipes, [...](http://www.sedfitting.org/Fitting.html)) which all have different strengths and weaknesses. With prospector, we have the advantage of being able to work with both FSPS and BPASS readily (and in principle, other models), which feature quite different treatments of massive star evolution and atmospheres.\n",
    "\n",
    "# Setting up prospector:\n",
    "First, make sure you're running in a python environment with 'the basics' (likely you already have these if you're running with conda):\n",
    "- numpy\n",
    "- scipy\n",
    "- astropy\n",
    "- matplotlib\n",
    "- h5py\n",
    "\n",
    "Next you'll need to set up some additional packages:\n",
    "- emcee or dynesty [pick your poison for domain exploration: MCMC, or nested sampling]\n",
    "- sedpy (for filters, likely optional here): `pip install astro-sedpy`\n",
    "- corner for pretty corner plots: `pip install corner`\n",
    "- *(definitely optional but nice:)* mpi4py for multiprocessing in the sampling step\n",
    "\n",
    "Next, we need to set up our actual galaxy modeling framework. In principle, this can be even more generally defined to allow you to plug-in your own bespoke complicated model. But for this tutorial and many simple fitting activites, FSPS is great.\n",
    "\n",
    "Note that we don't actually have to compile FSPS itself (make sure to note the citations in the readme though!); simply clone the repository somewhere convenient and make sure that you point the `$SPS_HOME` environment variable at it in the shell you are running python in (per [the python-fsps documentation](https://dfm.io/python-fsps/current/installation/)):\n",
    "```\n",
    "export SPS_HOME=\"/path/where/you/want/to/download/fsps\"\n",
    "git clone https://github.com/cconroy20/fsps.git $SPS_HOME\n",
    "```\n",
    "Then, you just need to install the python-fsps bindings themselves. One great thing about FSPS is that you can change the stellar libraries used; however, this can only be done at compile time. Conveniently, this flexibility is also built into the python-fsps bindings installation procedure: here, let's start with:\n",
    "```\n",
    "pip uninstall fsps  # if you already have python-fsps installed\n",
    "FFLAGS=\"-DMIST=0 -DPADOVA=0 -DMILES=0 -DBASEL=0 -DBPASS=1\" python -m pip install fsps --no-binary fsps\n",
    "```\n",
    "\n",
    "Finally, we're ready to install prospector itself: \n",
    "\n",
    "`python -m pip install astro-prospector`\n",
    "\n",
    "# Fetch some data to fit:\n",
    "Here I've included an example galaxy spectrum from the CLASSY survey, along with some helpful material discussed below. More on the provenance and format of these files can be found [here](https://archive.stsci.edu/hlsp/classy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3766c4c-c356-427b-8cbf-449ce6b48593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports and notebook setup\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551a50b-baab-4cfe-a77c-c5fdad5d6b72",
   "metadata": {},
   "source": [
    "First, let's open up and take a look at the example CLASSY spectrum we'll be analyzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469250fe-e577-43bd-ab94-8e32ea952c65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targnm = 'J0021+0052'\n",
    "\n",
    "specf = fits.open(f'data/hlsp_classy_hst_cos_{targnm.lower()}_multi_v1_coadded.fits')\n",
    "\n",
    "# the HR G130M+G160M data, in the rest frame and corrected for Galactic dust extinction:\n",
    "data_hr = specf['REST HR COADDED + GAL CORR'].data\n",
    "wlrest_raw = data_hr['wave']\n",
    "flux_raw = data_hr['flux density']\n",
    "err_raw = data_hr['error']\n",
    "\n",
    "# bin by 15 pixels (~0.17 A) to reduce noise\n",
    "smooth = 15\n",
    "wlrest = (np.convolve(wlrest_raw, np.ones(smooth), mode='same') / smooth)[smooth:-smooth:smooth]\n",
    "flux = (np.convolve(flux_raw, np.ones(smooth), mode='same') / smooth)[smooth:-smooth:smooth]\n",
    "err = (np.sqrt(np.convolve(err_raw**2., np.ones(smooth), mode='same')) / smooth)[smooth:-smooth:smooth]\n",
    "\n",
    "plt.plot(wlrest,flux)\n",
    "plt.ylim(0,10) # reduce viewed range; Lya swamps everything otherwise\n",
    "plt.xlabel('rest wavelength (Å)')\n",
    "plt.ylabel('Flambda (x10^15 erg/s/cm2/Å)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e50ead-20b6-475d-9ff3-3f3e047e3268",
   "metadata": {},
   "source": [
    "Looks like a blue UV continuum! There are a lot of stellar feature here, but they're hard to pick out against the transitions dominated by intervening ISM/outflow/MW absorption and Lya. Generally the first step in fitting UV spectra like this is to create a mask to block-out these and any other features we don't want to include in the fit; results can be very biased otherwise. This can be semi-automated with a linelist, but precise work will still generally require at least checking and refining this mask on an object-by-object or at least spectrograph-by-spectrograph basis. This is a little tedious, so for this example we'll load-up a mask we've already generated for this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cfaecc-51fa-4e85-a3bc-1ca66a0524bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedges_tab = np.genfromtxt(\n",
    "            f'data/{targnm}_maskedges.csv', delimiter=',')\n",
    "\n",
    "mask = np.zeros(wlrest.shape, dtype=bool)\n",
    "\n",
    "for edges in maskedges_tab:\n",
    "    mask = mask | ( (wlrest>edges[0]) & (wlrest<edges[1]) )\n",
    "\n",
    "mask = ~mask    # mask where 1 = use, 0 = masked\n",
    "mask = mask & np.isfinite(flux+err)\n",
    "\n",
    "plt.plot(wlrest[mask],flux[mask])\n",
    "plt.plot(wlrest,flux,zorder=-1,alpha=0.2,color='k')\n",
    "\n",
    "plt.ylim(np.min(flux[mask]), np.max(flux[mask]))\n",
    "plt.xlabel('rest wavelength (Å)')\n",
    "plt.ylabel('Flambda (x10^15 erg/s/cm2/Å)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae70a2-67b5-4ad3-9b9c-179ac402ee8b",
   "metadata": {},
   "source": [
    "Much better! Now we can proceed to a trial fit.\n",
    "\n",
    "Prospector is controlled fully in python, which is great (if you're into python) as it means you have quite a bit of flexibility in how you load your data in and fit it. This directory includes a minimal working example of the default parameter file adjusted to run a basic fit for this spectrum we just examined. Take a look at this file (`prospect_params.py`) in your favorite text editor to see the basic outline of how it works.\n",
    "\n",
    "To actually run it, we can either use the command line as-usual for a python script, or (convenient here) run it in debug mode with `--debug` inside a python interpreter or notebook.\n",
    "\n",
    "You should see this next cell spit-out some information about the model you've built, then updates about the emcee chain progress; and finally, a timestamped output file name which contains the results of the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a64442-5bf5-4ff9-b5dc-9a03c7882361",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run prospect_params.py --emcee --optimize --luminosity_distance 452 --object_redshift 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d786dbc-063f-419a-aeb2-3b222d644c6f",
   "metadata": {},
   "source": [
    "Hopefully that worked! Now we can load-in the results (stored in an HDF5 file) and make some basic diagnostic plots using handy utilities provided by prospector: Note, for this code to work properly, you need to make sure to reload the correct .h5 file - if you just reran it, unless you changed the defaults to overwrite, you'll have to update this to point to the new file each time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01169e7-8a96-4bd5-b3cc-8575d5c2c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prospect.io.read_results as reader\n",
    "\n",
    "res, obs, model = reader.results_from(\"prospector_test_run_~~TIMESTAMP~~_result.h5\")\n",
    "# Trace plots\n",
    "tfig = reader.traceplot(res)\n",
    "# Corner figure of posterior PDFs\n",
    "cfig = reader.subcorner(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3332c8-74d9-4b64-8472-c73eebd2ca5d",
   "metadata": {},
   "source": [
    "Hopefully you'll see some clustering of points in these diagrams! We're not going to worry about convergence of the MCMC chain in this quick tutorial, but note that this is an important extra step to assess for science-grade results.\n",
    "\n",
    "Now, let's take a look at the 'bestfit' and see if it looks any good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1dd26-574a-46d9-9f61-e58533799862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prospect.plotting.corner import quantile\n",
    "best = res[\"bestfit\"]\n",
    "\n",
    "plt.step(wlrest[mask],flux[mask])\n",
    "plt.step(wlrest,flux,zorder=-1,alpha=0.2,color='k')\n",
    "\n",
    "fitwl = res['obs']['wavelength']\n",
    "bestfl = best['spectrum']#/1.e-15\n",
    "import astropy.units as u\n",
    "def convert_to_maggies(flam,wls):\n",
    "    fl =  flam * u.erg/u.s/u.cm**2/u.angstrom\n",
    "    fl = fl.to(u.Jy, \n",
    "            equivalencies=u.spectral_density(wls*u.angstrom)\n",
    "            ).value / 3631.\n",
    "    return fl\n",
    "\n",
    "def convert_to_flam(maggies,wls):\n",
    "    fl = maggies * 3631. * u.Jy\n",
    "    fl = fl.to(u.erg/u.s/u.cm**2/u.angstrom,\n",
    "               equivalencies=u.spectral_density(wls*u.angstrom)\n",
    "              ).value\n",
    "    return fl\n",
    "\n",
    "print(bestfl)\n",
    "plt.plot(fitwl, convert_to_flam(bestfl,fitwl)/1.e-15)\n",
    "\n",
    "plt.ylim(np.min(flux[mask]), np.max(flux[mask]))\n",
    "plt.xlabel('rest wavelength (Å)')\n",
    "plt.ylabel('Flambda (x10^15 erg/s/cm2/Å)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2a676-e36c-4df6-abd5-428b1ace9e5c",
   "metadata": {},
   "source": [
    "You've just fit a UV spectrum using prospector! Hopefully the result looks vaguely reasonable!\n",
    "\n",
    "This basic tutorial was designed to get us up and running with a simple example, but we ignored plenty of the uncertainties inherent to this sort of fitting. As one option for the rest of the session, take a look at these ideas for things to improve/experiment with and try your hand at one (or a few!); you will likely find the prospector [documentation](https://prospect.readthedocs.io/en/latest/index.html) quite handy.\n",
    "- Zoom-in and take a closer look at this fit. What features are well fit? Which aren't? Should we believe the metallicity, etc we derive from this fit? Try restricting the wavelength range fit to exclude or focus-in on just the strong wind lines (NV, CIV): how does this change things?\n",
    "- In the example, we set up a simple stellar population (single-age) fit; but prospector has a huge amount of flexibility in the SFH approach. Experiment with e.g. a non-parametric star formation history; how different do the fits look? Is the history well-constrained by the spectrum?\n",
    "- Dust is a key ingredient here. Try out some different parameterizations / priors and see how it affects things.\n",
    "- We ignored nebular emission in this fit (and indeed, hopefully masked most of it intentionally). What happens when you include it?\n",
    "- We also neglected to account for the line spread function / resolution matching in this experiment. Try accounting for this with a simple fixed-velocity smoothing model, or a wavelenth-dependent approach (hint: the latter will end up being necessary here in this comparison with BPASS).\n",
    "- Often data reduction leaves the flux calibration for a spectrum far more uncertain than in this example with HST/COS. Explore how to account for this with prospector, and test out on a readjusted version of this spectrum.\n",
    "- We set FSPS/prospector up to use the BPASS library; as a comparison exercise, try switching to the FSPS-default MIST models. Can you achieve a similar fit using these libraries?\n",
    "- (Advanced group project I've been meaning to try:) In principle one can add any SPS models to the FSPS framework and thereby to prospector. Can we get e.g. a Starburst99 grid running in prospector (via FSPS, or directly in prospector)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305948b-1783-43b4-8404-bfdea9230a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
